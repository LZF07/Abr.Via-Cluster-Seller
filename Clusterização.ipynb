{"cells": [{"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "a6c15180-5c8a-4531-800f-68712b9cf74a"}}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(spark.sparkContext, 'be63ac50-4f9d-43f3-8f26-ad6572f65430', 'p-7bda336230f76ada26590bc6c4038045546d3287')\npc = project.project_context", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20210531015657-0019\nKERNEL_ID = 33a9c3f3-c474-4035-902f-70619ee5f2c5\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import pyspark\n\nfrom scipy.spatial.distance import cdist\nfrom pyspark.sql.window import Window \nimport numpy as np\nimport pandas as pd\npd.options.display.max_columns = 999\n\nfrom pyspark.sql.functions import *\nimport pyspark.sql.functions as F\nimport pyspark.sql.types as T\nfrom pyspark.sql import DataFrame\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom functools import reduce\n\nfrom botocore.client import Config\nimport ibm_boto3\n\nfrom datetime import datetime\nfrom datetime import datetime, timedelta\n\nimport sys\nimport shutil\nimport types", "execution_count": 2, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "0739d810-57ed-4da3-831a-c6031913c440"}}, "cell_type": "code", "source": "def normalize(x):\n    return [(x[n] - np.min(x)) / (np.max(x) - \n           np.min(x)) for n in range(len(x))]", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "credentials_1 = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-8c64e377-89e3-424a-b706-72ea9ab5fd59',\n    'IBM_API_KEY_ID': 'vNrUHeW9-R1HdOM2ld5PDpR96H0VdqryNzcmyVlNFne_',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'projetoviagrupo1-donotdelete-pr-q8ymlbqhihqlvv',\n    'VEN' : 'compilado_vendas.csv',\n    'CAR' : 'carrinho.csv'\n}\n\ncgsClient = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id = credentials_1['IBM_API_KEY_ID'],\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "path = '/home/spark/shared/tmp/'\ntry:\n    os.makedirs(path)\nexcept OSError:\n    shutil.rmtree(path)\n    print (\"Deletado diret\u00f3rio: %s\" % path)\n    print (\"Diret\u00f3rio criado com sucesso: %s\" % path)\n    os.makedirs(path)\nelse:\n    print (\"Diret\u00f3rio criado com sucesso: %s\" % path)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Deletado diret\u00f3rio: /home/spark/shared/tmp/\nDiret\u00f3rio criado com sucesso: /home/spark/shared/tmp/\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "def upload_file_cos(cos, local_file_name, credentials,key):  \n    \n    try:\n        res=cos.upload_file(Filename=local_file_name+key, Bucket=credentials['BUCKET'],Key=key)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print(key+' - File Uploaded -'+ (datetime.now() - timedelta(hours=3)).strftime(\"%d/%m/%Y %H:%M:%S\"))", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def download_file_cos(cos, local_file_name, credential): \n    \n    for i in credential:\n        if list(credential).index(i) > 4:\n\n            '''\n            Wrapper function to download a file from cloud object storage using the\n            credential dict provided and loading it into memory\n            '''\n            try:\n                res=cos.download_file(Bucket=credential['BUCKET'], Key=credential[i], Filename=local_file_name +credential[i])\n            except Exception as e:\n                print(credential[i] + ' - Exception', e)\n            else:\n                print(credential[i] + ' - File Downloaded')\n    \n    print(\"Done. -\"+(datetime.now() - timedelta(hours=3)).strftime(\"%d/%m/%Y %H:%M:%S\"))", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "download_file_cos(cgsClient, path, credentials_1)", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "compilado_vendas.csv - File Downloaded\ncarrinho.csv - File Downloaded\nDone. -30/05/2021 22:57:09\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "spark.read.option(\"header\",'true').csv(\"/home/spark/shared/tmp/compilado_vendas.csv\").createOrReplaceTempView(\"compilado_vendas\")\nspark.read.option(\"header\",'true').csv(\"/home/spark/shared/tmp/carrinho.csv\").createOrReplaceTempView(\"carrinho\")", "execution_count": 9, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "2651337d-121b-4c13-a9ef-148d5b80211c"}}, "cell_type": "code", "source": "def unionAll(*dfs):\n  df = reduce(DataFrame.unionAll, dfs)\n  return df", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(''' \nselect \nano,\nmes,\nidlojista,\nidbandeira,\nsum(valor) as valor,\nsum(frete) as frete,\nsum(valor_total) as valor_total,\nsum(itens) as itens,\nsum(ENVIOS) as ENVIOS,\nsum(atrasos) as atrasos,\nsum(media_atraso)/sum(atrasos) as media_atraso,\nsum(itens_entregues) as itens_entregues,\nsum(itens_cancelados) as itens_cancelados,\nsum(itens_fluxo) as itens_fluxo\n\nfrom compilado_vendas \ngroup by 1,2,3,4\n''').createOrReplaceTempView('sellers')", "execution_count": 11, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "b67136bb-7868-45c1-9f98-1a96e419ec3f"}}, "cell_type": "markdown", "source": "#### Clusteriza\u00e7\u00e3o IDBANDEIRA 7"}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "86ffbb7f-a7db-4a16-a15e-3ee9db055c17"}}, "cell_type": "code", "source": "df_principal  = spark.sql(''' select * from sellers where idbandeira = 7 and valor is not null ''')", "execution_count": 12, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "690ea1d7-7b32-4229-b01c-5cae23acc06d"}}, "cell_type": "code", "source": "df = df_principal.toPandas()", "execution_count": 13, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "6c2dbfea-1e90-482f-958c-46c6d1292e0f"}}, "cell_type": "code", "source": "df_kmeans = pd.DataFrame(data={'itens': normalize(pd.to_numeric(df.itens, errors='coerce')), 'valor': np.log1p(pd.to_numeric(df.valor, errors='coerce'))})", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_kmeans)\ndf['CLUSTER_GMV']=kmeans.labels_", "execution_count": 15, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "52e2d51b-013b-4f3d-99a6-1c0b8e16beee"}}, "cell_type": "code", "source": "df_7 = spark.createDataFrame(df)", "execution_count": 16, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "095024b5-4291-46b7-ae5f-27cf1a51ee03"}}, "cell_type": "markdown", "source": "#### Clusteriza\u00e7\u00e3o IDBANDEIRA 49"}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "a4e39cf3-5805-4fe9-903b-7f4ce368580f"}}, "cell_type": "code", "source": "df_principal  = spark.sql(''' select * from sellers where idbandeira = 49 and valor is not null ''')", "execution_count": 17, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "09c13596-e64c-4466-90fd-ea6f003863e9"}}, "cell_type": "code", "source": "df = df_principal.toPandas()", "execution_count": 18, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "f94780c8-2207-409b-b6ed-4ad02ad30760"}}, "cell_type": "code", "source": "df_kmeans = pd.DataFrame(data={'itens': normalize(pd.to_numeric(df.itens, errors='coerce')), 'valor': np.log1p(pd.to_numeric(df.valor, errors='coerce'))})", "execution_count": 19, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "535a4436-d475-4358-a0df-1839848d6867"}}, "cell_type": "code", "source": "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_kmeans)\ndf['CLUSTER_GMV']=kmeans.labels_", "execution_count": 20, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9a64d3b6-e3ac-411b-80c5-de1f1c136c32"}}, "cell_type": "code", "source": "df_49 = spark.createDataFrame(df)", "execution_count": 21, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "82335604-6c11-44ed-84b5-74ecf1164106"}}, "cell_type": "markdown", "source": "#### Clusteriza\u00e7\u00e3o IDBANDEIRA 343"}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "ed536cc8-fb7d-46ca-bfce-3465e2b2f759"}}, "cell_type": "code", "source": "df_principal  = spark.sql(''' select * from sellers where idbandeira = 343 and valor is not null ''')", "execution_count": 22, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "fbe635dc-8000-4587-ad92-17972516370e"}}, "cell_type": "code", "source": "df = df_principal.toPandas()", "execution_count": 23, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "d577aa0e-c2de-47ea-aa35-0ecf0f64da5a"}}, "cell_type": "code", "source": "df_kmeans = pd.DataFrame(data={'itens': normalize(pd.to_numeric(df.itens, errors='coerce')), 'valor': np.log1p(pd.to_numeric(df.valor, errors='coerce'))})", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_kmeans)\ndf['CLUSTER_GMV']=kmeans.labels_", "execution_count": 25, "outputs": []}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "58600346-a694-45ee-82b3-1ef4b2ae3a35"}}, "cell_type": "code", "source": "df_343 = spark.createDataFrame(df)", "execution_count": 26, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Juntando DF's"}, {"metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "cd046636-98cf-4811-b098-d80e6111d91a"}}, "cell_type": "code", "source": "df_principal = unionAll(*[df_7, df_49, df_343])\ndf_principal.createOrReplaceTempView('Clusters')", "execution_count": 27, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "cluster = spark.sql('''select \nc.*,\nT1.GMV as NEW_CLUSTER_GMV\n\nfrom Clusters c\ninner join\n(select\nrow_number() OVER(\n  PARTITION BY IDBANDEIRA\n  order by max_valor ASC\n) AS GMV,\n*\nfrom\n(select\nCLUSTER_GMV,\nmax(Valor) as max_valor,\nIDBANDEIRA\nfrom Clusters\ngroup by 1,3)) T1\non c.CLUSTER_GMV = T1.CLUSTER_GMV and c.IDBANDEIRA = T1.IDBANDEIRA\nwhere c.idbandeira = 7 and c.CLUSTER_GMV = 0''')\\\n.withColumn(\"CLUSTER_GMV\",col(\"NEW_CLUSTER_GMV\"))\\\n.drop(\"NEW_CLUSTER_GMV\")", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cluster.limit(10).toPandas()", "execution_count": 29, "outputs": [{"output_type": "execute_result", "execution_count": 29, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ano</th>\n      <th>mes</th>\n      <th>idlojista</th>\n      <th>idbandeira</th>\n      <th>valor</th>\n      <th>frete</th>\n      <th>valor_total</th>\n      <th>itens</th>\n      <th>ENVIOS</th>\n      <th>atrasos</th>\n      <th>media_atraso</th>\n      <th>itens_entregues</th>\n      <th>itens_cancelados</th>\n      <th>itens_fluxo</th>\n      <th>CLUSTER_GMV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021</td>\n      <td>3</td>\n      <td>17396</td>\n      <td>7</td>\n      <td>9402.80</td>\n      <td>33.90</td>\n      <td>9436.70</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020</td>\n      <td>5</td>\n      <td>13860</td>\n      <td>7</td>\n      <td>10399.20</td>\n      <td>215.10</td>\n      <td>10614.30</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>5</td>\n      <td>31312</td>\n      <td>7</td>\n      <td>29130.54</td>\n      <td>83.41</td>\n      <td>29213.95</td>\n      <td>39.0</td>\n      <td>39.0</td>\n      <td>1.0</td>\n      <td>10.000000</td>\n      <td>27.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020</td>\n      <td>5</td>\n      <td>17071</td>\n      <td>7</td>\n      <td>30013.21</td>\n      <td>3133.56</td>\n      <td>33146.77</td>\n      <td>69.0</td>\n      <td>69.0</td>\n      <td>10.0</td>\n      <td>13.050000</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020</td>\n      <td>6</td>\n      <td>16528</td>\n      <td>7</td>\n      <td>97142.00</td>\n      <td>12019.00</td>\n      <td>109161.00</td>\n      <td>62.0</td>\n      <td>62.0</td>\n      <td>5.0</td>\n      <td>21.400000</td>\n      <td>38.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021</td>\n      <td>4</td>\n      <td>14551</td>\n      <td>7</td>\n      <td>186900.56</td>\n      <td>10582.98</td>\n      <td>197483.54</td>\n      <td>447.0</td>\n      <td>447.0</td>\n      <td>16.0</td>\n      <td>2.375000</td>\n      <td>313.0</td>\n      <td>126.0</td>\n      <td>8.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>14612</td>\n      <td>7</td>\n      <td>62477.45</td>\n      <td>15223.83</td>\n      <td>77701.28</td>\n      <td>188.0</td>\n      <td>188.0</td>\n      <td>15.0</td>\n      <td>6.600000</td>\n      <td>121.0</td>\n      <td>66.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2019</td>\n      <td>7</td>\n      <td>16189</td>\n      <td>7</td>\n      <td>8185.00</td>\n      <td>527.68</td>\n      <td>8712.68</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>9.000000</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2020</td>\n      <td>6</td>\n      <td>10150</td>\n      <td>7</td>\n      <td>27781.82</td>\n      <td>5224.44</td>\n      <td>33006.26</td>\n      <td>63.0</td>\n      <td>63.0</td>\n      <td>13.0</td>\n      <td>17.923077</td>\n      <td>42.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2020</td>\n      <td>2</td>\n      <td>14551</td>\n      <td>7</td>\n      <td>97732.70</td>\n      <td>7965.72</td>\n      <td>105698.42</td>\n      <td>215.0</td>\n      <td>215.0</td>\n      <td>8.0</td>\n      <td>41.375000</td>\n      <td>108.0</td>\n      <td>57.0</td>\n      <td>50.0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    ano mes idlojista idbandeira      valor     frete  valor_total  itens  \\\n0  2021   3     17396          7    9402.80     33.90      9436.70    7.0   \n1  2020   5     13860          7   10399.20    215.10     10614.30    8.0   \n2  2020   5     31312          7   29130.54     83.41     29213.95   39.0   \n3  2020   5     17071          7   30013.21   3133.56     33146.77   69.0   \n4  2020   6     16528          7   97142.00  12019.00    109161.00   62.0   \n5  2021   4     14551          7  186900.56  10582.98    197483.54  447.0   \n6  2020   1     14612          7   62477.45  15223.83     77701.28  188.0   \n7  2019   7     16189          7    8185.00    527.68      8712.68    5.0   \n8  2020   6     10150          7   27781.82   5224.44     33006.26   63.0   \n9  2020   2     14551          7   97732.70   7965.72    105698.42  215.0   \n\n   ENVIOS  atrasos  media_atraso  itens_entregues  itens_cancelados  \\\n0     7.0      0.0           NaN              1.0               6.0   \n1     8.0      0.0           NaN              1.0               7.0   \n2    39.0      1.0     10.000000             27.0              12.0   \n3    69.0     10.0     13.050000             49.0              19.0   \n4    62.0      5.0     21.400000             38.0              24.0   \n5   447.0     16.0      2.375000            313.0             126.0   \n6   188.0     15.0      6.600000            121.0              66.0   \n7     5.0      2.0      9.000000              2.0               3.0   \n8    63.0     13.0     17.923077             42.0              21.0   \n9   215.0      8.0     41.375000            108.0              57.0   \n\n   itens_fluxo  CLUSTER_GMV  \n0          0.0            3  \n1          0.0            3  \n2          0.0            3  \n3          1.0            3  \n4          0.0            3  \n5          8.0            3  \n6          1.0            3  \n7          0.0            3  \n8          0.0            3  \n9         50.0            3  "}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "cluster.toPandas().to_csv('/home/spark/shared/tmp/cluster.csv', index=False)\nupload_file_cos(cgsClient, path,credentials_1,'cluster.csv')", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "cluster.csv - File Uploaded -30/05/2021 22:59:26\n", "name": "stdout"}]}], "metadata": {"application/vnd.databricks.v1+notebook": {"notebookName": "Material Clusteriza\u00e7\u00e3o", "dashboards": [], "notebookMetadata": {"pythonIndentUnit": 2}, "language": "python", "widgets": {}, "notebookOrigID": 1625265584039970}, "kernelspec": {"name": "python37", "display_name": "Python 3.7 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.7.10", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}